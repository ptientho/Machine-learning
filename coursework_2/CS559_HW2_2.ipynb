{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "379dad9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "691268e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0  1      2      3       4       5        6        7       8   \\\n",
       "0    842302  M  17.99  10.38  122.80  1001.0  0.11840  0.27760  0.3001   \n",
       "1    842517  M  20.57  17.77  132.90  1326.0  0.08474  0.07864  0.0869   \n",
       "2  84300903  M  19.69  21.25  130.00  1203.0  0.10960  0.15990  0.1974   \n",
       "3  84348301  M  11.42  20.38   77.58   386.1  0.14250  0.28390  0.2414   \n",
       "4  84358402  M  20.29  14.34  135.10  1297.0  0.10030  0.13280  0.1980   \n",
       "\n",
       "        9   ...     22     23      24      25      26      27      28      29  \\\n",
       "0  0.14710  ...  25.38  17.33  184.60  2019.0  0.1622  0.6656  0.7119  0.2654   \n",
       "1  0.07017  ...  24.99  23.41  158.80  1956.0  0.1238  0.1866  0.2416  0.1860   \n",
       "2  0.12790  ...  23.57  25.53  152.50  1709.0  0.1444  0.4245  0.4504  0.2430   \n",
       "3  0.10520  ...  14.91  26.50   98.87   567.7  0.2098  0.8663  0.6869  0.2575   \n",
       "4  0.10430  ...  22.54  16.67  152.20  1575.0  0.1374  0.2050  0.4000  0.1625   \n",
       "\n",
       "       30       31  \n",
       "0  0.4601  0.11890  \n",
       "1  0.2750  0.08902  \n",
       "2  0.3613  0.08758  \n",
       "3  0.6638  0.17300  \n",
       "4  0.2364  0.07678  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = 'wdbc.data'\n",
    "data = pd.read_csv(path,header=None)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "953b0595",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>...</td>\n",
       "      <td>25.380</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>...</td>\n",
       "      <td>24.990</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>...</td>\n",
       "      <td>23.570</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>...</td>\n",
       "      <td>14.910</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>...</td>\n",
       "      <td>22.540</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>M</td>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>...</td>\n",
       "      <td>25.450</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>M</td>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>...</td>\n",
       "      <td>23.690</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>M</td>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>...</td>\n",
       "      <td>18.980</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>M</td>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>...</td>\n",
       "      <td>25.740</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>B</td>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>...</td>\n",
       "      <td>9.456</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    1      2      3       4       5        6        7        8        9   \\\n",
       "0    M  17.99  10.38  122.80  1001.0  0.11840  0.27760  0.30010  0.14710   \n",
       "1    M  20.57  17.77  132.90  1326.0  0.08474  0.07864  0.08690  0.07017   \n",
       "2    M  19.69  21.25  130.00  1203.0  0.10960  0.15990  0.19740  0.12790   \n",
       "3    M  11.42  20.38   77.58   386.1  0.14250  0.28390  0.24140  0.10520   \n",
       "4    M  20.29  14.34  135.10  1297.0  0.10030  0.13280  0.19800  0.10430   \n",
       "..  ..    ...    ...     ...     ...      ...      ...      ...      ...   \n",
       "564  M  21.56  22.39  142.00  1479.0  0.11100  0.11590  0.24390  0.13890   \n",
       "565  M  20.13  28.25  131.20  1261.0  0.09780  0.10340  0.14400  0.09791   \n",
       "566  M  16.60  28.08  108.30   858.1  0.08455  0.10230  0.09251  0.05302   \n",
       "567  M  20.60  29.33  140.10  1265.0  0.11780  0.27700  0.35140  0.15200   \n",
       "568  B   7.76  24.54   47.92   181.0  0.05263  0.04362  0.00000  0.00000   \n",
       "\n",
       "         10  ...      22     23      24      25       26       27      28  \\\n",
       "0    0.2419  ...  25.380  17.33  184.60  2019.0  0.16220  0.66560  0.7119   \n",
       "1    0.1812  ...  24.990  23.41  158.80  1956.0  0.12380  0.18660  0.2416   \n",
       "2    0.2069  ...  23.570  25.53  152.50  1709.0  0.14440  0.42450  0.4504   \n",
       "3    0.2597  ...  14.910  26.50   98.87   567.7  0.20980  0.86630  0.6869   \n",
       "4    0.1809  ...  22.540  16.67  152.20  1575.0  0.13740  0.20500  0.4000   \n",
       "..      ...  ...     ...    ...     ...     ...      ...      ...     ...   \n",
       "564  0.1726  ...  25.450  26.40  166.10  2027.0  0.14100  0.21130  0.4107   \n",
       "565  0.1752  ...  23.690  38.25  155.00  1731.0  0.11660  0.19220  0.3215   \n",
       "566  0.1590  ...  18.980  34.12  126.70  1124.0  0.11390  0.30940  0.3403   \n",
       "567  0.2397  ...  25.740  39.42  184.60  1821.0  0.16500  0.86810  0.9387   \n",
       "568  0.1587  ...   9.456  30.37   59.16   268.6  0.08996  0.06444  0.0000   \n",
       "\n",
       "         29      30       31  \n",
       "0    0.2654  0.4601  0.11890  \n",
       "1    0.1860  0.2750  0.08902  \n",
       "2    0.2430  0.3613  0.08758  \n",
       "3    0.2575  0.6638  0.17300  \n",
       "4    0.1625  0.2364  0.07678  \n",
       "..      ...     ...      ...  \n",
       "564  0.2216  0.2060  0.07115  \n",
       "565  0.1628  0.2572  0.06637  \n",
       "566  0.1418  0.2218  0.07820  \n",
       "567  0.2650  0.4087  0.12400  \n",
       "568  0.0000  0.2871  0.07039  \n",
       "\n",
       "[569 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.drop(columns=[0])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a708aed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   1       569 non-null    object \n",
      " 1   2       569 non-null    float64\n",
      " 2   3       569 non-null    float64\n",
      " 3   4       569 non-null    float64\n",
      " 4   5       569 non-null    float64\n",
      " 5   6       569 non-null    float64\n",
      " 6   7       569 non-null    float64\n",
      " 7   8       569 non-null    float64\n",
      " 8   9       569 non-null    float64\n",
      " 9   10      569 non-null    float64\n",
      " 10  11      569 non-null    float64\n",
      " 11  12      569 non-null    float64\n",
      " 12  13      569 non-null    float64\n",
      " 13  14      569 non-null    float64\n",
      " 14  15      569 non-null    float64\n",
      " 15  16      569 non-null    float64\n",
      " 16  17      569 non-null    float64\n",
      " 17  18      569 non-null    float64\n",
      " 18  19      569 non-null    float64\n",
      " 19  20      569 non-null    float64\n",
      " 20  21      569 non-null    float64\n",
      " 21  22      569 non-null    float64\n",
      " 22  23      569 non-null    float64\n",
      " 23  24      569 non-null    float64\n",
      " 24  25      569 non-null    float64\n",
      " 25  26      569 non-null    float64\n",
      " 26  27      569 non-null    float64\n",
      " 27  28      569 non-null    float64\n",
      " 28  29      569 non-null    float64\n",
      " 29  30      569 non-null    float64\n",
      " 30  31      569 non-null    float64\n",
      "dtypes: float64(30), object(1)\n",
      "memory usage: 137.9+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "574833ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    357\n",
      "1    212\n",
      "Name: 1, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#map M to 1, B to 0\n",
    "data.loc[data.iloc[:,0] == 'M', 1] = 1\n",
    "data.loc[data.iloc[:,0] == 'B', 1] = 0\n",
    "#check if labels are not missing (label 0: 357, label 1: 212)\n",
    "print(data.iloc[:,0].value_counts())\n",
    "\n",
    "#prepare dataset for analysis\n",
    "data_arr = data.to_numpy()\n",
    "labels = data_arr[:,0] # dimension: (569,1)\n",
    "features = data_arr[:,1:] # dimension: (569,30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3c6d5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#stochastic gradient descent\n",
    "def sgd_gradient(features,labels,weights,step,epochs):\n",
    "    for e in range(0,epochs):\n",
    "        data = np.hstack((features,labels))\n",
    "        np.random.shuffle(data)\n",
    "        for i in range(0,len(labels)):\n",
    "            w = np.zeros((features.shape[1],1)) #element of weights\n",
    "            a = np.dot(features[i,:],weights) #prediction using sigmoid function. Features dim(1,30) weight dim(30,1)\n",
    "            sigm = 1.0/(1+math.exp(-a))\n",
    "            \n",
    "            for j in range(0,len(weights)): #iterate through weights,elementwise\n",
    "                w[j] = w[j] + (sigm - labels[i,:])*features[i,j]\n",
    "            #update\n",
    "            for k in range(0,len(weights)): #update weights after complete each sample\n",
    "                weights[k] = weights[k] - step*w[k]/len(labels)\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98fca6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mini-batch gradient descent from Lasso\n",
    "def get_batches(features,labels,batch_size):\n",
    "    batches = []\n",
    "    data = np.hstack((features,labels))\n",
    "    n_batch = data.shape[0]\n",
    "    \n",
    "    for i in range(0, n_batch):\n",
    "        mini_batch = data[i*batch_size:(i+1)*batch_size,:]\n",
    "        features_mini = mini_batch[:,:-1]\n",
    "        labels_mini = mini_batch[:,-1].reshape((-1,1))\n",
    "        batches.append((features_mini,labels_mini)) #append pairs of (features_mini, labels_mini) to batches\n",
    "        \n",
    "        if n_batch % batch_size != 0: #if data is small than batch_size\n",
    "            mini_batch = data[i*batch_size:n_batch]\n",
    "            features_mini = mini_batch[:,:-1]\n",
    "            labels_mini = mini_batch[:,-1].reshape((-1,1))\n",
    "            batches.append((features_mini,labels_mini))\n",
    "        \n",
    "    return batches\n",
    "\n",
    "def mnb_gradient(features,labels,weights,step,epochs):\n",
    "    \n",
    "    for e in range(0,epochs):\n",
    "        data = np.hstack((features,labels))\n",
    "        np.random.shuffle(data)\n",
    "        mini_batches = get_batches(features,labels,batch_size=50)\n",
    "        \n",
    "        for m in mini_batches:\n",
    "            f,l = m #get individual mini batch\n",
    "            w = np.zeros((f.shape[1],1)) #element of weights\n",
    "            \n",
    "            for i in range(0,len(l)):\n",
    "                \n",
    "                a = np.dot(f[i,:],weights) #f dimension(1,30) weights dimension(30,1) \n",
    "                sigm = 1/(1+math.exp(-a)) #prediction using sigmoid function\n",
    "                \n",
    "                for j in range(0,len(weights)):\n",
    "                    w[j] = w[j] + (sigm - l[i,:])*f[i,j]\n",
    "    \n",
    "            for k in range(0,len(weights)): #update weights after complete each batch\n",
    "                weights[k] =  weights[k] - step*w[k]/len(labels)\n",
    "    \n",
    "    return weights\n",
    "            \n",
    "\n",
    "def predict(features,weights_updated):\n",
    "    threshold = 0.5\n",
    "    Y_pred = []\n",
    "   \n",
    "    fb = np.c_[np.ones((len(features[:,1]),1)),features]\n",
    "    \n",
    "    for i in range(0,len(features[:,1])):\n",
    "        \n",
    "        a = np.dot(fb[i,:],weights_updated) #features dim(1,30) weights dim(30,1)\n",
    "        \n",
    "        sigm = 1/(1+math.exp(-a)) #predict using sigmoid function\n",
    "        \n",
    "        pc1 = np.round(sigm,2) #class 1 class2: pc2 = 1-pc1\n",
    "        if pc1 < threshold: #pc2 > threshold\n",
    "            Y_pred.append(0) #class 1: benign\n",
    "        else:\n",
    "            Y_pred.append(1) #class 2: malignant\n",
    "    \n",
    "    return np.array(Y_pred).reshape((-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9817b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_sgd(features,labels,step=0.01,iterations=100):\n",
    "    \n",
    "    weights = np.ones((features.shape[1]+1,1))\n",
    "    features_wbias = np.c_[np.ones((len(labels),1)),features]\n",
    "\n",
    "    w_trained = sgd_gradient(features_wbias,labels,weights,step,iterations)\n",
    "\n",
    "    return w_trained\n",
    "\n",
    "def train_mnb(features,labels,step=0.01,iterations=100):\n",
    "    \n",
    "    weights = np.ones((features.shape[1]+1,1))\n",
    "    features_wbias = np.c_[np.ones((len(labels),1)),features]\n",
    "   \n",
    "    w_trained = mnb_gradient(features_wbias,labels,weights,step,iterations)\n",
    "\n",
    "    return w_trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2a0cf42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "report for SGD model iteration 0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   benign(-)       0.85      0.87      0.86        45\n",
      "malignant(+)       0.91      0.90      0.90        68\n",
      "\n",
      "    accuracy                           0.88       113\n",
      "   macro avg       0.88      0.88      0.88       113\n",
      "weighted avg       0.89      0.88      0.89       113\n",
      "\n",
      "report for MNB model iteration 0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   benign(-)       0.87      0.91      0.89        45\n",
      "malignant(+)       0.94      0.91      0.93        68\n",
      "\n",
      "    accuracy                           0.91       113\n",
      "   macro avg       0.91      0.91      0.91       113\n",
      "weighted avg       0.91      0.91      0.91       113\n",
      "\n",
      "report for SGD model iteration 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   benign(-)       0.90      0.86      0.88        64\n",
      "malignant(+)       0.83      0.88      0.85        49\n",
      "\n",
      "    accuracy                           0.87       113\n",
      "   macro avg       0.86      0.87      0.87       113\n",
      "weighted avg       0.87      0.87      0.87       113\n",
      "\n",
      "report for MNB model iteration 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   benign(-)       0.92      0.91      0.91        64\n",
      "malignant(+)       0.88      0.90      0.89        49\n",
      "\n",
      "    accuracy                           0.90       113\n",
      "   macro avg       0.90      0.90      0.90       113\n",
      "weighted avg       0.90      0.90      0.90       113\n",
      "\n",
      "report for SGD model iteration 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   benign(-)       0.94      0.92      0.93        74\n",
      "malignant(+)       0.85      0.90      0.88        39\n",
      "\n",
      "    accuracy                           0.91       113\n",
      "   macro avg       0.90      0.91      0.90       113\n",
      "weighted avg       0.91      0.91      0.91       113\n",
      "\n",
      "report for MNB model iteration 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   benign(-)       0.97      0.95      0.96        74\n",
      "malignant(+)       0.90      0.95      0.92        39\n",
      "\n",
      "    accuracy                           0.95       113\n",
      "   macro avg       0.94      0.95      0.94       113\n",
      "weighted avg       0.95      0.95      0.95       113\n",
      "\n",
      "report for SGD model iteration 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   benign(-)       0.97      0.94      0.96        83\n",
      "malignant(+)       0.85      0.93      0.89        30\n",
      "\n",
      "    accuracy                           0.94       113\n",
      "   macro avg       0.91      0.94      0.92       113\n",
      "weighted avg       0.94      0.94      0.94       113\n",
      "\n",
      "report for MNB model iteration 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   benign(-)       1.00      0.95      0.98        83\n",
      "malignant(+)       0.88      1.00      0.94        30\n",
      "\n",
      "    accuracy                           0.96       113\n",
      "   macro avg       0.94      0.98      0.96       113\n",
      "weighted avg       0.97      0.96      0.97       113\n",
      "\n",
      "report for SGD model iteration 4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   benign(-)       0.97      0.86      0.91        90\n",
      "malignant(+)       0.62      0.91      0.74        23\n",
      "\n",
      "    accuracy                           0.87       113\n",
      "   macro avg       0.80      0.88      0.82       113\n",
      "weighted avg       0.90      0.87      0.88       113\n",
      "\n",
      "report for MNB model iteration 4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   benign(-)       0.98      0.89      0.93        90\n",
      "malignant(+)       0.68      0.91      0.78        23\n",
      "\n",
      "    accuracy                           0.89       113\n",
      "   macro avg       0.83      0.90      0.85       113\n",
      "weighted avg       0.91      0.89      0.90       113\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#normalize features\n",
    "features_normed = StandardScaler().fit_transform(features) # dimension: (569,30)\n",
    "labels = labels.reshape((-1,1)) # dimension: (569,1)\n",
    "data = np.hstack((features_normed,labels))\n",
    "#print(labels[1,0])\n",
    "#split data for train-test use cross validation\n",
    "k_fold = 5\n",
    "data_test_size = int(np.floor((1/k_fold)*data.shape[0]))\n",
    "label_names = ['benign(-)','malignant(+)']\n",
    "for k in range(0,k_fold):\n",
    "    \n",
    "    data_test = data[k*data_test_size:(k+1)*data_test_size,:]  \n",
    "    data_train = np.delete(data,slice(k*data_test_size,(k+1)*data_test_size),0)\n",
    "    \n",
    "    features_train = data_train[:,:-1]\n",
    "    labels_train = data_train[:,-1].reshape((-1,1))\n",
    "    \n",
    "    features_test = data_test[:,:-1]\n",
    "    labels_test = data_test[:,-1].reshape((-1,1))\n",
    "    labels_test=labels_test.flatten().astype('int32')\n",
    "    \n",
    "    #train SGD\n",
    "    W_trained_sgd = train_sgd(features_train,labels_train)\n",
    "    #predict SGD\n",
    "    labels_pred_sgd = predict(features_test,W_trained_sgd)\n",
    "    labels_pred_sgd=labels_pred_sgd.flatten().astype('int32')\n",
    "    print('report for SGD model iteration {}'.format(k))\n",
    "    print(classification_report(labels_test,labels_pred_sgd,target_names=label_names))\n",
    "    \n",
    "    #train Mini-batch\n",
    "    W_trained_mnb = train_mnb(features_train,labels_train)\n",
    "    #predict MNB\n",
    "    labels_pred_mnb = predict(features_test,W_trained_mnb)\n",
    "    labels_pred_mnb = labels_pred_mnb.flatten().astype('int32')\n",
    "    print('report for MNB model iteration {}'.format(k))\n",
    "    print(classification_report(labels_test,labels_pred_mnb,target_names=label_names))\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
